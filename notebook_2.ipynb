{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For single word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1. Finding nearest 5 semantically similar words with similarity in vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRTsMX7N_ecR",
        "outputId": "b3be8b63-6cd1-46c0-c0be-390ad4d73ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "straightforward: 0.7460168600082397\n",
            "Simple: 0.7108175754547119\n",
            "uncomplicated: 0.6297484636306763\n",
            "simplest: 0.6171397566795349\n",
            "easy: 0.5990299582481384\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Function to find top 5 related words\n",
        "def find_related_words(word, topn=5):\n",
        "    if word in model.key_to_index:\n",
        "        return model.most_similar(word, topn=topn)\n",
        "    else:\n",
        "        return f\"Word '{word}' not in vocabulary\"\n",
        "\n",
        "# Input word\n",
        "input_word = 'simple'\n",
        "related_words = find_related_words(input_word)\n",
        "\n",
        "# Display results\n",
        "for word, similarity in related_words:\n",
        "    print(f\"{word}: {similarity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2. Finding nearest 5 semantically similar words and then finding the semantic distance between two given words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1KwxlAwAxva",
        "outputId": "3a1ee346-d0a1-4b25-bbea-475b09ee39af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 related words to 'simple':\n",
            "straightforward: 0.7460168600082397\n",
            "Simple: 0.7108175754547119\n",
            "uncomplicated: 0.6297484636306763\n",
            "simplest: 0.6171397566795349\n",
            "easy: 0.5990299582481384\n",
            "\n",
            "Semantic similarity distance between 'simple' and 'easy': 0.4009700417518616\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Function to find top 5 related words\n",
        "def find_related_words(word, topn=5):\n",
        "    if word in model.key_to_index:\n",
        "        return model.most_similar(word, topn=topn)\n",
        "    else:\n",
        "        return f\"Word '{word}' not in vocabulary\"\n",
        "\n",
        "# Function to find semantic similarity distance\n",
        "def similarity_distance(word1, word2):\n",
        "    if word1 in model.key_to_index and word2 in model.key_to_index:\n",
        "        similarity = model.similarity(word1, word2)\n",
        "        distance = 1 - similarity\n",
        "        return distance\n",
        "    else:\n",
        "        return f\"One or both words '{word1}', '{word2}' not in vocabulary\"\n",
        "\n",
        "# Input word\n",
        "input_word = 'simple'\n",
        "related_words = find_related_words(input_word)\n",
        "\n",
        "# Display results\n",
        "print(f\"Top 5 related words to '{input_word}':\")\n",
        "for word, similarity in related_words:\n",
        "    print(f\"{word}: {similarity}\")\n",
        "\n",
        "# # Calculate and display semantic similarity distance\n",
        "# specific_word = 'easy'\n",
        "# distance = similarity_distance(input_word, specific_word)\n",
        "# print(f\"\\nSemantic similarity distance between '{input_word}' and '{specific_word}': {distance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3. Finding the semantic distance between two given words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate and display semantic similarity distance\n",
        "specific_word = 'easy'\n",
        "distance = similarity_distance(input_word, specific_word)\n",
        "print(f\"\\nSemantic similarity distance between '{input_word}' and '{specific_word}': {distance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 4. Finding semantic similarity and semantic distance of nearest 5 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVrOeADvBtLL",
        "outputId": "ba2eec4c-a3cf-47c5-d75a-44cab38d3e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "straightforward: Cosine Similarity = 0.7460168600082397, Semantic Distance = 0.25398313999176025\n",
            "Simple: Cosine Similarity = 0.7108175754547119, Semantic Distance = 0.28918248414993286\n",
            "uncomplicated: Cosine Similarity = 0.6297484636306763, Semantic Distance = 0.37025147676467896\n",
            "simplest: Cosine Similarity = 0.6171397566795349, Semantic Distance = 0.3828602433204651\n",
            "easy: Cosine Similarity = 0.5990299582481384, Semantic Distance = 0.4009700417518616\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Function to find top 5 related words based on semantic distance\n",
        "def find_related_words(word, topn=5):\n",
        "    if word in model.key_to_index:\n",
        "        # Retrieve similar words and their cosine similarities\n",
        "        similar_words = model.most_similar(word, topn=topn)\n",
        "        return similar_words\n",
        "    else:\n",
        "        return f\"Word '{word}' not in vocabulary\"\n",
        "\n",
        "# Function to compute semantic distance (cosine similarity)\n",
        "def semantic_distance(word1, word2):\n",
        "    if word1 in model.key_to_index and word2 in model.key_to_index:\n",
        "        similarity = model.similarity(word1, word2)\n",
        "        return similarity\n",
        "    else:\n",
        "        return f\"One or both words '{word1}' and '{word2}' not in vocabulary\"\n",
        "\n",
        "# Input word\n",
        "input_word = 'simple'\n",
        "related_words = find_related_words(input_word)\n",
        "\n",
        "# Display results\n",
        "for word, similarity in related_words:\n",
        "    distance = semantic_distance(input_word, word)\n",
        "    print(f\"{word}: Cosine Similarity = {similarity}, Semantic Distance = {1 - distance}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 5. Finding 5 nearest words to the given word (using word2vec)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ctrG3YFHwY",
        "outputId": "4b5d3470-ce0d-4f19-b0fc-1faf57e2bca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words similar to 'happy': ['glad', 'pleased', 'ecstatic', 'overjoyed', 'thrilled']\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load the pretrained Word2Vec model\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "def find_similar_words(word, topn=5):\n",
        "    try:\n",
        "        similar_words = model.most_similar(word, topn=topn)\n",
        "        return [w for w, score in similar_words]\n",
        "    except KeyError:\n",
        "        return f\"The word '{word}' not found in the vocabulary.\"\n",
        "\n",
        "# Example usage\n",
        "input_word = \"happy\"\n",
        "similar_words = find_similar_words(input_word)\n",
        "print(f\"Words similar to '{input_word}': {similar_words}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 6. Finding Nth nearest word with similarity and semantic difference to the given word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1_9GkeQFI2-",
        "outputId": "a6636cd6-40ab-49c7-df02-5c062a82bad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12th similar word to 'simple': intuitive with Cosine Similarity = 0.5120431780815125, Semantic Distance = 0.48795682191848755\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Function to find the N-th related word\n",
        "def find_nth_similar_word(word, rank):\n",
        "    if word not in model.key_to_index:\n",
        "        return f\"Word '{word}' not in vocabulary\"\n",
        "\n",
        "    similar_words = model.most_similar(word, topn=rank + 1)  # Get top (rank + 1) similar words\n",
        "    if rank < 1 or rank > len(similar_words):\n",
        "        return f\"Rank {rank} is out of range\"\n",
        "\n",
        "    nth_similar_word = similar_words[rank - 1]  # Get the N-th similar word\n",
        "    return nth_similar_word\n",
        "\n",
        "# Input word and rank\n",
        "input_word = 'simple'\n",
        "rank = 12  # Change this to the desired rank (e.g., 2nd similar, 18th similar, etc.)\n",
        "\n",
        "# Find the N-th similar word\n",
        "nth_similar_word = find_nth_similar_word(input_word, rank)\n",
        "\n",
        "# Display result\n",
        "if isinstance(nth_similar_word, str):\n",
        "    print(nth_similar_word)\n",
        "else:\n",
        "    word, similarity = nth_similar_word\n",
        "    print(f\"{rank}th similar word to '{input_word}': {word} with Cosine Similarity = {similarity}, Semantic Distance = {1 - similarity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 7. Finding 5 nearest words to the given word (using GloVe)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAJtx_9qGRu7",
        "outputId": "a2c5f61a-d84f-41ea-cafc-1cf9b8e96676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words similar to 'cold': ['rough', 'snow', 'rain', 'dry', 'bit']\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load the pretrained GloVe model\n",
        "model = api.load(\"glove-twitter-25\")\n",
        "\n",
        "def find_similar_words(word, topn=5):\n",
        "    try:\n",
        "        similar_words = model.most_similar(word, topn=topn)\n",
        "        return [w for w, score in similar_words]\n",
        "    except KeyError:\n",
        "        return f\"The word '{word}' not found in the vocabulary.\"\n",
        "\n",
        "# Example usage\n",
        "input_word = \"cold\"\n",
        "similar_words = find_similar_words(input_word)\n",
        "print(f\"Words similar to '{input_word}': {similar_words}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQNiHGmUXrIj",
        "outputId": "9937fa26-55fd-456f-81d8-e11d22a5ba59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sentence: president greets the press in chicago\n",
            "Transformed sentence: President greet the media in baltimore\n"
          ]
        }
      ],
      "source": [
        "# Ensure you have the necessary libraries installed\n",
        "!pip install gensim nltk\n",
        "\n",
        "# Import the required libraries\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Load stopwords from NLTK\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to find the most similar word\n",
        "def find_most_similar_word(word):\n",
        "    if word in model.key_to_index:\n",
        "        # Retrieve the most similar word\n",
        "        similar_word, _ = model.most_similar(word, topn=1)[0]\n",
        "        return similar_word\n",
        "    else:\n",
        "        return word  # Return the original word if not in vocabulary\n",
        "\n",
        "# Function to transform the sentence\n",
        "def transform_sentence(sentence):\n",
        "    words = sentence.split()\n",
        "    transformed_words = []\n",
        "    for word in words:\n",
        "        if word.lower() not in stop_words:\n",
        "            similar_word = find_most_similar_word(word)\n",
        "            transformed_words.append(similar_word)\n",
        "        else:\n",
        "            transformed_words.append(word)\n",
        "    return ' '.join(transformed_words)\n",
        "\n",
        "# Input sentence\n",
        "input_sentence = \"president greets the press in chicago\"\n",
        "transformed_sentence = transform_sentence(input_sentence)\n",
        "\n",
        "# Display result\n",
        "print(f\"Original sentence: {input_sentence}\")\n",
        "print(f\"Transformed sentence: {transformed_sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9W9bBTClIgf",
        "outputId": "b79c288a-7f40-486f-9733-d211ccf1b45f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sentence: president greets the press in chicago\n",
            "Transformed sentence: President greet the media in baltimore\n"
          ]
        }
      ],
      "source": [
        "# Ensure you have the necessary libraries installed\n",
        "!pip install gensim nltk\n",
        "\n",
        "# Import the required libraries\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Load stopwords from NLTK\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function for text cleaning and preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove non-alphanumeric characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Tokenize text\n",
        "    words = nltk.word_tokenize(text)\n",
        "    return words\n",
        "\n",
        "# Function to find the most similar word\n",
        "def find_most_similar_word(word):\n",
        "    if word in model.key_to_index:\n",
        "        # Retrieve the most similar word\n",
        "        similar_word, _ = model.most_similar(word, topn=1)[0]\n",
        "        return similar_word\n",
        "    else:\n",
        "        return word  # Return the original word if not in vocabulary\n",
        "\n",
        "# Function to transform the sentence\n",
        "def transform_sentence(sentence):\n",
        "    words = preprocess_text(sentence)\n",
        "    transformed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words:\n",
        "            similar_word = find_most_similar_word(word)\n",
        "            transformed_words.append(similar_word)\n",
        "        else:\n",
        "            transformed_words.append(word)\n",
        "    return ' '.join(transformed_words)\n",
        "\n",
        "# Input sentence\n",
        "input_sentence = \"president greets the press in chicago\"\n",
        "transformed_sentence = transform_sentence(input_sentence)\n",
        "\n",
        "# Display result\n",
        "print(f\"Original sentence: {input_sentence}\")\n",
        "print(f\"Transformed sentence: {transformed_sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNbo1b31lsWz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
